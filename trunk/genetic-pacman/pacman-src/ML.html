<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="GENERATOR" content="Microsoft FrontPage 5.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Machine Learning: Pacman Capture the Flag</title>
<style type="text/css">
<!--
.style1      { font-style: italic; font-weight: bold }
-->
</style>
<link href="projects.css" rel="stylesheet" type="text/css">
<style type="text/css">
<!--
.style2      { color: #990000 }
-->
</style>
</head>

<body>

<h2>Machine Learning: Pacman Capture the Flag</h2>

<blockquote>
<center>
<img src="capture_the_flag.png" width="540" height="210">
</center>
  <p><cite><center>Enough of defense,<br>
  Onto enemy terrain.<br>
  Capture all their food!</center></cite></p>
</blockquote>


<h3>Introduction</h3>

<p>This project involves a multi-player capture-the-flag variant of
Pacman, where agents control both Pacman and ghosts in coordinated
team-based strategies.  Your team will try to eat the food on the far
side of the map, while defending the food on your home side.  The code
and the supporting documents are available as a <a href="ml.zip">zip
archive</a>.

<table border="0" cellpadding="10">
  <tr><td><b>Key files to read:</b></td></tr>

  <tr><td><code><a href="docs/capture.html">capture.py</a></code> </td>
  <td>The main file that runs games locally.  This file also describes the new capture the flag GameState type and rules.</td></tr>
<!--
  <tr><td><code><a href="docs/pacclient.html">pacclient.py</a></code> </td>
  <td>The main file that runs games over the network. </td></tr>-->

  <tr><td><code><a href="docs/captureAgents.html">captureAgents.py</a></code> </td>
  <td>Specification and helper methods for capture agents. </td></tr>

  <tr><td><code><a href="docs/baselineTeam.html">baselineTeam.py</a></code> </td>
  <td>Example code that defines two very basic reflex agents, to help you get started.</td></tr>

  <tr><td><code><a href="docs/myTeam.html">myTeam.py</a></code> </td>
  <td>This is where you define your own agents for inclusion in the nightly tournament.  (This is the only file that you submit.)</td></tr>

  <tr><th colspan="2" align="left"><b>Supporting files (do not modify):</b></th></tr>

  <tr><td><code><a href="docs/game.html">game.py</a></code></td>
  <td>The logic behind how the Pacman world works.  This file describes several supporting types like AgentState, Agent, Direction, and Grid.</td></tr>

  <tr><td><code><a href="docs/util.html">util.py</a></code></td>
  <td>Useful data structures for implementing search algorithms.</td></tr>

  <tr><td><code><a href="docs/distanceCalculator.html">distanceCalculator.py</a></code> </td>
  <td>Computes shortest paths between all maze positions. </td></tr>

  <tr><td><code><a href="docs/graphicsDisplay.html">graphicsDisplay.py</a></code></td>
  <td>Graphics for Pacman</td></tr>

    <tr><td><code><a href="docs/graphicsUtils.html">graphicsUtils.py</a></code></td>
  <td>Support for Pacman graphics</td></tr>

  <tr><td><code><a href="docs/textDisplay.html">textDisplay.py</a></code></td>
  <td>ASCII graphics for Pacman</td></tr>

    <tr><td><code><a href="docs/keyboardAgents.html">keyboardAgents.py</a></code></td>
  <td>Keyboard interfaces to control Pacman</td></tr>

<!--  <tr><td><code><a href="docs/pygameDisplay.html">pygameDisplay.py</a></code></td>
  <td>New faster graphics for Pacman (in development)</td></tr>

  <tr><td><code><a href="docs/pygameAgents.html">pygameAgents.py</a></code></td>
  <td>Keyboard agents for the pygame graphics package</td></tr>
  -->

    <tr><td><code><a href="docs/layout.html">layout.py</a></code></td>
  <td>Code for reading layout files and storing their contents</td></tr>

</table>

<p><strong>Academic Dishonesty:</strong> While we won't grade contests, we still expect you not to falsely represent your work.  <em>Please</em> don't let us down.

<h3>Rules of Pacman Capture the Flag</h3>

<b>Layout:</b> The Pacman map is now divided into two halves: blue (right) and red (left).  Red agents (which all have even indices) must defend the red food while trying to eat the blue food.  When on the red side, a red agent is a ghost.  When crossing into enemy territory, the agent becomes a Pacman.

<p><b>Scoring:</b>  When a Pacman eats a food dot, the food is permanently removed and one point is scored for that Pacman's team.  Red team scores are positive, while Blue team scores are negative.

<p><b>Eating Pacman:</b> When a Pacman is eaten by an opposing ghost, the Pacman returns to its starting position (as a ghost).  No points are awarded for eating an opponent.

<p><b>Power capsules:</b> If Pacman eats a power capsule, agents on the opposing team become "scared" for the next 40 moves, or until they are eaten and respawn, whichever comes sooner.  Agents that are "scared" are susceptible while in the form of ghosts (i.e. while on their own team's side) to being eaten by Pacman.  Specifically, if Pacman collides with a "scared" ghost, Pacman is unaffected and the ghost respawns at its starting position (no longer in the "scared" state).

<p><b>Observations:</b> Agents can only observe an opponent's configuration (position and direction) if they or their teammate is within 5 squares (Manhattan distance).  In addition, an agent always gets a noisy distance reading for each agent on the board, which can be used to approximately locate unobserved opponents.

<p><b>Winning:</b> A game ends when one team eats all but two of the opponents' dots.  Games are also limited to 1200 agent moves (300 moves per each of the four agents).  If this move limit is reached, whichever team has eaten the most food wins. If the score is zero (i.e., tied) this is recorded as a tie game.


<h3> Submission Instructions </h3>

Please submit your code and write-up to the appropriate drop-box on Angel.


<h3>Getting Started</h3>

By default, you can run a game with the simple <code>baselineTeam</code> that the staff has provided:

<pre>python capture.py</pre>

<p>A wealth of options are available to you:

<pre>python capture.py --help</pre>

There are four slots for agents, where agents 0 and 2 are always on the red team, and 1 and 3 are on the blue team.  Agents are created by agent factories (one for Red, one for Blue).  See the section on designing agents for a description of the agents invoked above.

The only team that we provide is the <code>baselineTeam</code>. It is chosen by default as both the red and blue team, but as an example of how to choose teams:

<pre>python capture.py -r baselineTeam -b baselineTeam</pre>

which specifies that the red team <code>-r</code> and the blue team <code>-b</code> are both created from <code><a href="docs/baselineTeam.html">baselineTeam.py</a></code>.

To control one of the four agents with the keyboard, pass the appropriate option:

<pre>python capture.py --keys0</pre>

The arrow keys control your character, which will change from ghost to Pacman when crossing the center line.

<h4>Layouts</h4>

By default, all games are run on the <code>defaultcapture</code> layout. To test your agent on other layouts, use the <code>-l</code> option.
In particular, you can generate random layouts by specifying <code>RANDOM[seed]</code>. For example, <code>-l RANDOM13</code> will use a map randomly generated with seed 13.


<h3>Designing Agents</h3>

Unlike project 2, an agent now has the more complex job of trading off
offense versus defense and effectively functioning as both a ghost and
a Pacman in a team setting.

<p><b>Baseline Team:</b> To kickstart your agent design, we have provided you with a team of two baseline agents, defined in <code><a href="docs/baselineTeam.html">baselineTeam.py</a></code>.  They are both quite bad.  The <code>OffensiveReflexAgent</code> moves toward the closest food on the opposing side.  The <code>DefensiveReflexAgent</code> wanders around on its own side and tries to chase down invaders it happens to see.

<p><b>File naming:</b> For the purpose of testing or running games locally, you can define a team of agents in any arbitrarily-named python file.  When submitting to the nightly tournament, however, you must define your agents in <code><a href="docs/myTeam.html">myTeam.py</a></code> (and you must also create a <code>name.txt</code> file that specifies your team name).

<p><b>Interface:</b> The <code>GameState</code> in <code><a href="docs/capture.html">capture.py</a></code> should look familiar, but contains new methods like <code>getRedFood</code>, which gets a grid of food on the red side (note that the grid is the size of the board, but is only true for cells on the red side with food).  Also, note that you can list a team's indices with <code>getRedTeamIndices</code>, or test membership with <code>isOnRedTeam</code>.

<p><b>Distance Calculation: </b>To facilitate agent development, we provide code in <code><a href="docs/distanceCalculator.html">distanceCalculator.py</a></code> to supply shortest path maze distances.

<p>To get started designing your own agent, we recommend subclassing the <code>CaptureAgent</code> class.  This provides access to several convenience methods.  Some useful methods are:

<pre>
  def getFood(self, gameState):
    """
    Returns the food you're meant to eat. This is in the form
    of a matrix where m[x][y]=true if there is food you can
    eat (based on your team) in that square.
    """

  def getFoodYouAreDefending(self, gameState):
    """
    Returns the food you're meant to protect (i.e., that your
    opponent is supposed to eat). This is in the form of a
    matrix where m[x][y]=true if there is food at (x,y) that
    your opponent can eat.
    """

  def getOpponents(self, gameState):
    """
    Returns agent indices of your opponents. This is the list
    of the numbers of the agents (e.g., red might be "1,3,5")
    """

  def getTeam(self, gameState):
    """
    Returns agent indices of your team. This is the list of
    the numbers of the agents (e.g., red might be "1,3,5")
    """

  def getScore(self, gameState):
    """
    Returns how much you are beating the other team by in the
    form of a number that is the difference between your score
    and the opponents score. This number is negative if you're
    losing.
    """

  def getMazeDistance(self, pos1, pos2):
    """
    Returns the distance between two points; These are calculated using the provided
    distancer object.

    If distancer.getMazeDistances() has been called, then maze distances are available.
    Otherwise, this just returns Manhattan distance.
    """

  def getPreviousObservation(self):
    """
    Returns the GameState object corresponding to the last
    state this agent saw (the observed state of the game last
    time this agent moved - this may not include all of your
    opponent's agent locations exactly).
    """

  def getCurrentObservation(self):
    """
    Returns the GameState object corresponding this agent's
    current observation (the observed state of the game - this
    may not include all of your opponent's agent locations
    exactly).
    """

  def debugDraw(self, cells, color, clear=False):
    """
    Draws a colored box on each of the cells you specify. If clear is True,
    will clear all old drawings before drawing on the specified cells.
    This is useful for debugging the locations that your code works with.

    color: list of RGB values between 0 and 1 (i.e. [1,0,0] for red)
    cells: list of game positions to draw on  (i.e. [(20,5), (3,22)])
    """


</pre>




<h3>Acknowledgements</h3>

<!-- Many thanks to Jeremy Cowles for implementing the tournament infrastructure. --> Thanks to Barak Michener and Ed Karuna for providing <!-- online networking infrastructure, --> improved graphics and debugging help.

<p>

<img src="capture_the_flag2.png" width="785" height="444" />

<p> Have fun!  Please bring our attention to any problems you discover.
</body>

</html>
